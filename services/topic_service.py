import os
import json
from gensim import corpora, models

lda_model=None
dictionary =None
# --- ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ LDA ---
def train_lda_model(texts, num_topics=10):
    global lda_model, dictionary

    texts_words = [text.split() for text in texts]
    dictionary = corpora.Dictionary(texts_words)
    corpus = [dictionary.doc2bow(text) for text in texts_words]

    lda_model = models.LdaModel(
        corpus=corpus,
        id2word=dictionary,
        num_topics=num_topics,
        random_state=42,
        update_every=1,
        passes=10,
        alpha='auto',
        per_word_topics=True
    )

# --- Ø­ÙØ¸ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªÙˆØ¨ÙŠÙƒØ§Øª Ù„ÙƒÙ„ ÙˆØ«ÙŠÙ‚Ø© ÙÙŠ Ù…Ù„Ù JSON ---
def save_document_topics(texts, output_path ="models/"):
    if lda_model is None or dictionary is None:
        raise ValueError("ÙŠØ¬Ø¨ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹")
   
    texts_words = [text.split() for text in texts]
    corpus = [dictionary.doc2bow(text) for text in texts_words]

    doc_topics = {}
    for i, bow in enumerate(corpus):
        topics = lda_model.get_document_topics(bow)
        sorted_topics = sorted(topics, key=lambda x: x[1], reverse=True)
        top_topic = sorted_topics[0][0] if sorted_topics else -1
        doc_topics[str(i)] = top_topic

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(doc_topics, f, ensure_ascii=False, indent=2)
    print(f"âœ… ØªÙ… Ø­ÙØ¸ ØªÙˆØ¨ÙŠÙƒØ§Øª Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ ÙÙŠ: {output_path}")
# --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…Ù† Ù†Øµ ÙˆØ§Ø­Ø¯ ---
def get_text_topics(text, top_n=3):
    if lda_model is None or dictionary is None:
        return []
    bow = dictionary.doc2bow(text.split())
    topics = lda_model.get_document_topics(bow)
    topics_sorted = sorted(topics, key=lambda x: x[1], reverse=True)[:top_n]

    topic_words = []
    for topic_id, score in topics_sorted:
        terms = lda_model.show_topic(topic_id, topn=3)
        words = [w for w, _ in terms]
        topic_words.append({
            "topic_id": topic_id,
            "score": round(score, 3),
            "words": words
        })
    return topic_words

# --- ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª ---
def load_lda_models(model_path="models/lda_model", dict_path="models/lda_dict"):
    global lda_model, dictionary
    if os.path.exists(model_path) and os.path.exists(dict_path):
        lda_model = models.LdaModel.load(model_path)
        dictionary = corpora.Dictionary.load(dict_path)
        print("ğŸ“¦ LDA model loaded from disk")
        return True
    return False

# --- Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª ---
def save_lda_models(model_path="models/lda_model", dict_path="models/lda_dict"):
    if lda_model is not None:
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        lda_model.save(model_path)
        dictionary.save(dict_path)
