{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36de3b2-05a3-46fd-8472-9cf7e6c4d0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحميل 10000 وثيقة...\n",
      "✅ تم تحميل 20000 وثيقة...\n",
      "✅ تم تحميل 30000 وثيقة...\n",
      "✅ تم تحميل 40000 وثيقة...\n",
      "✅ تم تحميل 50000 وثيقة...\n",
      "✅ تم تحميل 60000 وثيقة...\n",
      "✅ تم تحميل 70000 وثيقة...\n",
      "✅ تم تحميل 80000 وثيقة...\n",
      "✅ تم تحميل 90000 وثيقة...\n",
      "✅ تم تحميل 100000 وثيقة...\n",
      "✅ تم تحميل 110000 وثيقة...\n",
      "✅ تم تحميل 120000 وثيقة...\n",
      "✅ تم تحميل 130000 وثيقة...\n",
      "✅ تم تحميل 140000 وثيقة...\n",
      "✅ تم تحميل 150000 وثيقة...\n",
      "✅ تم تحميل 160000 وثيقة...\n",
      "✅ تم تحميل 170000 وثيقة...\n",
      "✅ تم تحميل 180000 وثيقة...\n",
      "✅ تم تحميل 190000 وثيقة...\n",
      "✅ تم تحميل 200000 وثيقة...\n",
      "✅ تم تحميل 210000 وثيقة...\n",
      "✅ تم تحميل 220000 وثيقة...\n",
      "✅ تم تحميل 230000 وثيقة...\n",
      "✅ تم تحميل 240000 وثيقة...\n",
      "✅ تم تحميل 250000 وثيقة...\n",
      "✅ تم تحميل 260000 وثيقة...\n",
      "✅ تم تحميل 270000 وثيقة...\n",
      "✅ تم تحميل 280000 وثيقة...\n",
      "✅ تم تحميل 290000 وثيقة...\n",
      "✅ تم تحميل 300000 وثيقة...\n",
      "✅ تم تحميل 310000 وثيقة...\n",
      "✅ تم تحميل 320000 وثيقة...\n",
      "✅ تم تحميل 330000 وثيقة...\n",
      "✅ تم تحميل 340000 وثيقة...\n",
      "✅ تم تحميل 350000 وثيقة...\n",
      "✅ تم تحميل 360000 وثيقة...\n",
      "✅ تم تحميل 370000 وثيقة...\n",
      "✅ تم تحميل 380000 وثيقة...\n",
      "✅ تم تحميل 390000 وثيقة...\n",
      "✅ تم تحميل 400000 وثيقة...\n",
      "✅ تم تحميل 410000 وثيقة...\n",
      "✅ تم تحميل 420000 وثيقة...\n",
      "✅ تم تحميل 430000 وثيقة...\n",
      "✅ تم تحميل 440000 وثيقة...\n",
      "✅ تم تحميل 450000 وثيقة...\n",
      "✅ تم تحميل 460000 وثيقة...\n",
      "✅ تم تحميل 470000 وثيقة...\n",
      "✅ تم تحميل 480000 وثيقة...\n",
      "✅ تم تحميل 490000 وثيقة...\n",
      "✅ تم تحميل 500000 وثيقة...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ir_datasets\n",
    "\n",
    "dataset = ir_datasets.load(\"msmarco-passage/train\")\n",
    "\n",
    "seen_ids = set()\n",
    "\n",
    "doc_iterator = dataset.docs_iter()\n",
    "\n",
    "count = 0\n",
    "\n",
    "docs_data = []\n",
    "\n",
    "def safe_text(text):\n",
    "    try:\n",
    "        return text.encode('latin1').decode('utf-8')\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "while count < 500000:\n",
    "\n",
    "    try:\n",
    "        doc = next(doc_iterator)\n",
    "\n",
    "        # تجاهل التكرارات\n",
    "        if doc.doc_id in seen_ids:\n",
    "            continue\n",
    "        seen_ids.add(doc.doc_id)\n",
    "\n",
    "        text_clean = safe_text(doc.text)\n",
    "\n",
    "        docs_data.append({\n",
    "            \"id\": doc.doc_id,\n",
    "            \"text\": text_clean\n",
    "        })\n",
    "        count += 1\n",
    "\n",
    "        if count % 10000 == 0:\n",
    "            print(f\"✅ تم تحميل {count} وثيقة...\")\n",
    "\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# 6. إنشاء DataFrame\n",
    "df = pd.DataFrame(docs_data)\n",
    "\n",
    "df.drop(df.loc[df['id']==''].index,inplace=True)\n",
    "\n",
    "df['id']=df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24c05ee9-4c50-4bd1-a80b-a59067164401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir = r\"..\\data\\msmarco_train\\raw\"\n",
    "output_file = os.path.join(output_dir, \"raw_msmarco_train.json\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df.to_json(output_file, orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691d2200-a5fd-4829-9979-2e6ad0067a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحميل 10000 وثيقة...\n",
      "✅ تم تحميل 20000 وثيقة...\n",
      "✅ تم تحميل 30000 وثيقة...\n",
      "✅ تم تحميل 40000 وثيقة...\n",
      "✅ تم تحميل 50000 وثيقة...\n",
      "✅ تم تحميل 60000 وثيقة...\n",
      "✅ تم تحميل 70000 وثيقة...\n",
      "✅ تم تحميل 80000 وثيقة...\n",
      "✅ تم تحميل 90000 وثيقة...\n",
      "✅ تم تحميل 100000 وثيقة...\n",
      "✅ تم تحميل 110000 وثيقة...\n",
      "✅ تم تحميل 120000 وثيقة...\n",
      "✅ تم تحميل 130000 وثيقة...\n",
      "✅ تم تحميل 140000 وثيقة...\n",
      "✅ تم تحميل 150000 وثيقة...\n",
      "✅ تم تحميل 160000 وثيقة...\n",
      "✅ تم تحميل 170000 وثيقة...\n",
      "✅ تم تحميل 180000 وثيقة...\n",
      "✅ تم تحميل 190000 وثيقة...\n",
      "✅ تم تحميل 200000 وثيقة...\n",
      "✅ تم تحميل 210000 وثيقة...\n",
      "✅ تم تحميل 220000 وثيقة...\n",
      "✅ تم تحميل 230000 وثيقة...\n",
      "✅ تم تحميل 240000 وثيقة...\n",
      "✅ تم تحميل 250000 وثيقة...\n",
      "✅ تم تحميل 260000 وثيقة...\n",
      "✅ تم تحميل 270000 وثيقة...\n",
      "✅ تم تحميل 280000 وثيقة...\n",
      "✅ تم تحميل 290000 وثيقة...\n",
      "✅ تم تحميل 300000 وثيقة...\n",
      "✅ تم تحميل 310000 وثيقة...\n",
      "✅ تم تحميل 320000 وثيقة...\n",
      "✅ تم تحميل 330000 وثيقة...\n",
      "✅ تم تحميل 340000 وثيقة...\n",
      "✅ تم تحميل 350000 وثيقة...\n",
      "✅ تم تحميل 360000 وثيقة...\n",
      "✅ تم تحميل 370000 وثيقة...\n",
      "📌 انتهت الوثائق الموجودة في الداتا سيت.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ir_datasets\n",
    "\n",
    "dataset = ir_datasets.load(\"antique/train\")\n",
    "\n",
    "seen_ids = set()\n",
    "\n",
    "doc_iterator = dataset.docs_iter()\n",
    "\n",
    "count = 0\n",
    "\n",
    "docs_data = []\n",
    "\n",
    "def safe_text(text):\n",
    "    try:\n",
    "        return text.encode('latin1').decode('utf-8')\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "while count < 404000:\n",
    "\n",
    "    try:\n",
    "        doc = next(doc_iterator)\n",
    "\n",
    "        # تجاهل التكرارات\n",
    "        if doc.doc_id in seen_ids:\n",
    "            continue\n",
    "        seen_ids.add(doc.doc_id)\n",
    "\n",
    "        text_clean = safe_text(doc.text)\n",
    "\n",
    "        docs_data.append({\n",
    "            \"id\": doc.doc_id,\n",
    "            \"text\": text_clean\n",
    "        })\n",
    "        count += 1\n",
    "\n",
    "        if count % 10000 == 0:\n",
    "            print(f\"✅ تم تحميل {count} وثيقة...\")\n",
    "            \n",
    "    except StopIteration:\n",
    "        print(\"📌 انتهت الوثائق الموجودة في الداتا سيت.\")\n",
    "        break\n",
    "    except Exception:\n",
    "        continue  # تجاوز أي خطأ غير متوقع \n",
    "# 6. إنشاء DataFrame\n",
    "df = pd.DataFrame(docs_data)\n",
    "\n",
    "df.drop(df.loc[df['id']==''].index,inplace=True)\n",
    "\n",
    "df['id']=df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30f1903-ab76-44d4-8e0c-31da9504f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir = r\"..\\data\\antique_train\\raw\"\n",
    "output_file = os.path.join(output_dir, \"raw_antique_train.json\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df.to_json(output_file, orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea47923-2b1e-493b-92d2-27c71f7a9726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم تحميل 10000 وثيقة...\n",
      "✅ تم تحميل 20000 وثيقة...\n",
      "✅ تم تحميل 30000 وثيقة...\n",
      "✅ تم تحميل 40000 وثيقة...\n",
      "✅ تم تحميل 50000 وثيقة...\n",
      "✅ تم تحميل 60000 وثيقة...\n",
      "✅ تم تحميل 70000 وثيقة...\n",
      "✅ تم تحميل 80000 وثيقة...\n",
      "✅ تم تحميل 90000 وثيقة...\n",
      "✅ تم تحميل 100000 وثيقة...\n",
      "✅ تم تحميل 110000 وثيقة...\n",
      "✅ تم تحميل 120000 وثيقة...\n",
      "✅ تم تحميل 130000 وثيقة...\n",
      "✅ تم تحميل 140000 وثيقة...\n",
      "✅ تم تحميل 150000 وثيقة...\n",
      "✅ تم تحميل 160000 وثيقة...\n",
      "✅ تم تحميل 170000 وثيقة...\n",
      "✅ تم تحميل 180000 وثيقة...\n",
      "✅ تم تحميل 190000 وثيقة...\n",
      "✅ تم تحميل 200000 وثيقة...\n",
      "✅ تم تحميل 210000 وثيقة...\n",
      "✅ تم تحميل 220000 وثيقة...\n",
      "✅ تم تحميل 230000 وثيقة...\n",
      "✅ تم تحميل 240000 وثيقة...\n",
      "✅ تم تحميل 250000 وثيقة...\n",
      "✅ تم تحميل 260000 وثيقة...\n",
      "✅ تم تحميل 270000 وثيقة...\n",
      "✅ تم تحميل 280000 وثيقة...\n",
      "✅ تم تحميل 290000 وثيقة...\n",
      "✅ تم تحميل 300000 وثيقة...\n",
      "✅ تم تحميل 310000 وثيقة...\n",
      "✅ تم تحميل 320000 وثيقة...\n",
      "✅ تم تحميل 330000 وثيقة...\n",
      "✅ تم تحميل 340000 وثيقة...\n",
      "✅ تم تحميل 350000 وثيقة...\n",
      "✅ تم تحميل 360000 وثيقة...\n",
      "✅ تم تحميل 370000 وثيقة...\n",
      "✅ تم تحميل 380000 وثيقة...\n",
      "✅ تم تحميل 390000 وثيقة...\n",
      "✅ تم تحميل 400000 وثيقة...\n",
      "✅ تم تحميل 410000 وثيقة...\n",
      "✅ تم تحميل 420000 وثيقة...\n",
      "✅ تم تحميل 430000 وثيقة...\n",
      "✅ تم تحميل 440000 وثيقة...\n",
      "✅ تم تحميل 450000 وثيقة...\n",
      "✅ تم تحميل 460000 وثيقة...\n",
      "✅ تم تحميل 470000 وثيقة...\n",
      "✅ تم تحميل 480000 وثيقة...\n",
      "✅ تم تحميل 490000 وثيقة...\n",
      "✅ تم تحميل 500000 وثيقة...\n",
      "✅ تم تحميل 510000 وثيقة...\n",
      "✅ تم تحميل 520000 وثيقة...\n",
      "📌 انتهت الوثائق الموجودة في الداتا سيت.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ir_datasets\n",
    "\n",
    "dataset = ir_datasets.load(\"beir/quora/test\")\n",
    "\n",
    "seen_ids = set()\n",
    "\n",
    "doc_iterator = dataset.docs_iter()\n",
    "\n",
    "count = 0\n",
    "\n",
    "docs_data = []\n",
    "\n",
    "def safe_text(text):\n",
    "    try:\n",
    "        return text.encode('latin1').decode('utf-8')\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "while count < 524000:\n",
    "\n",
    "    try:\n",
    "        doc = next(doc_iterator)\n",
    "\n",
    "        # تجاهل التكرارات\n",
    "        if doc.doc_id in seen_ids:\n",
    "            continue\n",
    "        seen_ids.add(doc.doc_id)\n",
    "\n",
    "        text_clean = safe_text(doc.text)\n",
    "\n",
    "        docs_data.append({\n",
    "            \"id\": doc.doc_id,\n",
    "            \"text\": text_clean\n",
    "        })\n",
    "        count += 1\n",
    "\n",
    "        if count % 10000 == 0:\n",
    "            print(f\"✅ تم تحميل {count} وثيقة...\")\n",
    "            \n",
    "    except StopIteration:\n",
    "        print(\"📌 انتهت الوثائق الموجودة في الداتا سيت.\")\n",
    "        break\n",
    "    except Exception:\n",
    "        continue  # تجاوز أي خطأ غير متوقع \n",
    "# 6. إنشاء DataFrame\n",
    "df = pd.DataFrame(docs_data)\n",
    "\n",
    "df.drop(df.loc[df['id']==''].index,inplace=True)\n",
    "\n",
    "df['id']=df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e06564-700d-433f-9127-69dc8280babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir = r\"..\\data\\beir\\raw\"\n",
    "output_file = os.path.join(output_dir, \"raw_beir_quora_test.json\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df.to_json(output_file, orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78239d0-767b-41a3-969a-e8f0611784ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Top 10 TF-IDF Results:\n",
      "Doc ID: 738009, Score: 0.4979\n",
      "Text: bacterioplankton /bakËŒtÉªÉ™rÉªÉ™(ÊŠ)ËˆplaÅ‹(k)tÉ™n/ /bakËˆtÉªÉ™rÉªÉ™(ÊŠ)ËŒplaÅ‹(k)tÉ™n/\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 557534, Score: 0.3997\n",
      "Text: A relatively stable level, period, or state: Mortgage rates declined, then reached a plateau. intr.v. pla·teaued, pla·teau·ing, pla·teaus. To reach a stable level; level off: The tension seemed to grow by degrees, then it plateaued (Tom Clancy).\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 843141, Score: 0.3858\n",
      "Text: 1. What is a Project Labor Agreement (PLA)? A project labor agreement (PLA) is a construction labor agreement between an owner and a regional building trades council, representing all the construction craft unions in a given geographical area. PLAs are agreements that establish uniform terms and conditions for all construction craft employees, as well as all construction contractors on a specific construction project. Each PLA is specific to one project only.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 843146, Score: 0.3837\n",
      "Text: A PLA is a multi-employer, multi-union, pre-hire collective bargaining agreement that PLA proponents market to public and private construction owners as a tool to systemize labor relations between multiple construction trade unions and contractors on a specific construction site.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 950385, Score: 0.3747\n",
      "Text: In 2010, PLA had the second highest consumption volume of any bioplastic of the world. The name polylactic acid does not comply with IUPAC standard nomenclature, and is potentially ambiguous or confusing, because PLA is not a polyacid (polyelectrolyte), but rather a polyester.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 348548, Score: 0.3346\n",
      "Text: Army day is observed annually on August 1. It is a day to commemorate the PLA's contribution to China and army veterans are honored on this day.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 738170, Score: 0.3344\n",
      "Text: In this lesson you will learn how to say thank you (Merci) and please (sâ€™il vous plait) plaÃ®t In. French you will also learn familiar and formal ways to say please as well as how to â€˜say thank you veryâ€™. muchay please and the polite form say â€œsâ€™il vous plait â€œ. PlaÃ®t if you are saying pleased to a, friend peer for somebody who is younger than yourself â€œ sayâ€™s il te â€œ. Plait plaÃ®t there are several ways ofâ€™saying you. Re welcome the easiest and most common way of saying â€œ this is â€œ. de rien\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 299331, Score: 0.3328\n",
      "Text: Share to:   The most affected organ is the heart (organ) itself. The cause of a heart attack is when the arteries that feed the heart are blocked either by a clot or build-up of pla â€¦ que.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 625380, Score: 0.3251\n",
      "Text: Whereas PLA is known to have low melt strength and does not show strain hardening, co-agent modification of PLA led to substantial strain hardening, suggesting improved melt strength. Improvement of melt strength and crystallization rate of polylactic acid and its blends... with medium-chain-length polyhydroxyalkanoate through reactive modification\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 953882, Score: 0.3231\n",
      "Text: One way, and the simplest, is to look on the barrel , if the weapon saysBlackPowder Only, it is not an original. Otherwise the blue book of muzzleloader values is a good plaâ€¦ce to start. 1 person found this useful.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📌 Top 10 BERT Results:\n",
      "Doc ID: 201742, Score: 0.5182\n",
      "Text: Hey guys i am currently 15 years old and i plan to play D1 soccer. I am a sophmore whis is studying a year up and has taken 1 A.P. course. I currently hold a 3.4 and a 3.7 weighted. I play for one of the best teams in the country (Ranked top 100) out of 3,500 teams in my country.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 680939, Score: 0.4983\n",
      "Text: In the United States, the sport of association football is mainly referred to as soccer, as the term football is primarily used to refer to the sport of American football. The highest professional soccer league in the U.S. is Major League Soccer.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 702063, Score: 0.4846\n",
      "Text: He works hand in hand with two assistant referees or even three during big games. Here is a look at the soccer referee responsibilities, which are focused on ensuring a smooth running of the game. Pre-Game Responsibilities. Prior to the match, the referee must sure that the players are ready to play and all their jewelry is removed.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 149487, Score: 0.4785\n",
      "Text: The rough and tumble NFL is a league where every game counts and anything can happen on any given Sunday. When an NFL great dies, we remember their finest moments on the gridiron. This memorial site was created to honor and remember players, coaches and others associated with the National Football League.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 829492, Score: 0.4742\n",
      "Text: dropkick-drop and kick (a ball) as it touches the ground, as for a field goal. drop-kick. football, football game-any of various games played with a ball (round or oval) in which two teams try to kick or carry or propel the ball into each other's goal.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 442473, Score: 0.4727\n",
      "Text: â€“ Word-for-word from page 20 on U.S. Soccerâ€™s role with the National Womenâ€™s Soccer League: â€œNational Womenâ€™s Soccer League, LLC (â€˜NWSLâ€™) was formed on December 12, 2012 and functions as a professional womenâ€™s soccer league.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 695514, Score: 0.4714\n",
      "Text: Degrees. Unlike most other careers, becoming a professional football player is not dependent on the degree you pursue during college. Players who attend college on athletic scholarships with the hope of eventually making it to the NFL are occasionally known for taking light course loads.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 352601, Score: 0.4677\n",
      "Text: FA stands for Football Association in England. The FA was founded in 1863 as the governing body of the game [of soccer] in England.The FA is responsible for all regulatory a â€¦ spects of the game of football in England.. --From TheFA.Com.he most win fa cup team is Manchester united and they get the cup for 11 times while arsenal won the cup for 10 times, tottenham 8 times, Liverpool 7 times, Aston vila 7 time â€¦ s and Chelsea 6 times. 24 people found this useful.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 318124, Score: 0.4669\n",
      "Text: An intermediate goal is a goal that can be achieved in 1-5 yrs. It is one of 4 basic types of goals: short-term, intermediate, and long-term... !!!Good luck!! 3 people found this useful.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 842247, Score: 0.4660\n",
      "Text: An association football (soccer) match is presided over by a referee, whom the Laws of the Game give full authority to enforce the Laws of the Game in connection with the match to which he has been appointed (Law 5). The referee is oftentimes assisted by two assistant referees, and sometimes by a fourth official.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📌 Top 10 Hybrid Results (TF-IDF 0.4, BERT 0.6):\n",
      "Doc ID: 680939, Score: 0.3980\n",
      "Text: In the United States, the sport of association football is mainly referred to as soccer, as the term football is primarily used to refer to the sport of American football. The highest professional soccer league in the U.S. is Major League Soccer.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 674317, Score: 0.3818\n",
      "Text: Statistics and facts on the National Football League (NFL) The National Football League (NFL) is a professional football league in the United States. The league was founded in 1920 as the American Professional Football Association and played its inaugural season with eleven teams.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 738009, Score: 0.3810\n",
      "Text: bacterioplankton /bakËŒtÉªÉ™rÉªÉ™(ÊŠ)ËˆplaÅ‹(k)tÉ™n/ /bakËˆtÉªÉ™rÉªÉ™(ÊŠ)ËŒplaÅ‹(k)tÉ™n/\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 588177, Score: 0.3675\n",
      "Text: But for each of those 92 professional football players who have made it to the Super Bowl, there are approximately 11,828 students playing high school football in this country. In the 2012-2013 school year, 14,048 U.S. high schools fielded teams to play 11-man per side American tackle football.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 352602, Score: 0.3636\n",
      "Text: As the first football association, it does not use the national name English in its title. The FA is based at Wembley Stadium, London. The FA is a member of the British Olympic Association, meaning that the FA has control over the men's and women's Great Britain Olympic football team.All of England's professional football teams are members of the Football Association.he FA rejoined FIFA in 1946 and participated in their first World Cup in 1950. One of the first actions of the Football Association was to request the expulsion of the German and Japanese national football associations for their countries' role in World War II.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 913840, Score: 0.3633\n",
      "Text: Fantasy Football Glossary. New to fantasy football? Or simply want to learn all of the lingo that makes up the game? Lucky for you, NFL.com has put together a glossary of fantasy football terms so you don't spend your next season with more questions than answers.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 808484, Score: 0.3605\n",
      "Text: National Football League on television. The television rights to broadcast National Football League (NFL) games are the most lucrative and expensive rights of any American sport. Television brought professional football into prominence in the modern era after World War II.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 829492, Score: 0.3528\n",
      "Text: dropkick-drop and kick (a ball) as it touches the ground, as for a field goal. drop-kick. football, football game-any of various games played with a ball (round or oval) in which two teams try to kick or carry or propel the ball into each other's goal.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 635062, Score: 0.3520\n",
      "Text: In football you have a running back that carries the ball, and in Jugger you have a â€˜qwikâ€™ that is the only one on your team that can pickup the â€˜ballâ€™ and score. You also have enforcers that are very much like offensive linemen on a football team.\n",
      "--------------------------------------------------------------------------------\n",
      "Doc ID: 438146, Score: 0.3516\n",
      "Text: American football. American football. Running Football Player isolated on white Stock Photo. Running Football Player isolated on white Stock Photo. Football, soccer match. Grass close up. Night event lights on the stadium. Football, soccer match. Grass close up. Night event lights on the stadium.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# 📌 المكتبات المطلوبة\n",
    "# =============================================\n",
    "import joblib\n",
    "import numpy as np\n",
    "import re\n",
    "import html\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# =============================================\n",
    "# 📌 دالة التنظيف المستخدمة في TF-IDF\n",
    "# =============================================\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def advanced_preprocess(text):\n",
    "    text = html.unescape(text)\n",
    "    text = ''.join(c for c in text if c.isprintable())\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    words = [stemmer.stem(w) for w in text.split() if w not in stop_words and len(w) > 2]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# =============================================\n",
    "# 📁 تحميل بيانات TF-IDF\n",
    "# =============================================\n",
    "tfidf_doc_ids = joblib.load(r\"..\\data\\msmarco_train\\index\\TFIDF\\doc_ids_msmarco_train.joblib\")\n",
    "tfidf_matrix = joblib.load(r\"..\\data\\msmarco_train\\index\\TFIDF\\tfidf_matrix_msmarco_train.joblib\")\n",
    "tfidf_vectorizer = joblib.load(\n",
    "    r\"..\\data\\msmarco_train\\index\\TFIDF\\tfidf_vectorizer_msmarco_train.joblib\"\n",
    ")\n",
    "inverted_index_data = joblib.load(r\"..\\data\\msmarco_train\\index\\TFIDF\\tfidf_inverted_index.joblib\")\n",
    "\n",
    "# =============================================\n",
    "# 📁 تحميل بيانات BERT\n",
    "# =============================================\n",
    "bert_embeddings = np.load(r\"..\\data\\msmarco_train\\index\\bert\\bert_embeddings.npy\")\n",
    "bert_doc_ids = joblib.load(r\"..\\data\\msmarco_train\\index\\bert\\doc_ids.joblib\")\n",
    "\n",
    "# =============================================\n",
    "# 📦 تحميل نموذج BERT للاستعلامات\n",
    "# =============================================\n",
    "bert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# =============================================\n",
    "# 📁 تحميل ملف JSONL للنصوص\n",
    "# =============================================\n",
    "docs_dict = {}\n",
    "with open(r\"..\\data\\msmarco_train\\raw\\raw_msmarco_train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            doc = json.loads(line)\n",
    "            doc_id = doc.get(\"id\")   \n",
    "            doc_text = doc.get(\"text\") \n",
    "            if doc_id is not None:\n",
    "                docs_dict[str(doc_id)] = doc_text\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"⚠️ تخطي سطر غير صالح: {e}\")\n",
    "\n",
    "# =============================================\n",
    "# 🔍 البحث باستخدام TF-IDF فقط\n",
    "# =============================================\n",
    "def search_tfidf_with_inverted_index(query, inverted_index_data, tfidf_vectorizer, tfidf_matrix, doc_ids, docs_dict, top_k=10, candidate_size=100):\n",
    "    # 1. تنظيف الاستعلام\n",
    "    cleaned_query = advanced_preprocess(query)\n",
    "    query_terms = cleaned_query.split()\n",
    "    if not query_terms:\n",
    "        return []\n",
    "\n",
    "    # 2. ترشيح الوثائق باستخدام الفهرس المعكوس (مجموع درجات tfidf)\n",
    "    doc_scores = {}\n",
    "    for term in query_terms:\n",
    "        if term in inverted_index_data[\"inverted_index\"]:\n",
    "            postings = inverted_index_data[\"inverted_index\"][term]\n",
    "            for doc_id, score in postings:\n",
    "                if doc_id not in doc_scores:\n",
    "                    doc_scores[doc_id] = 0.0\n",
    "                doc_scores[doc_id] += score\n",
    "\n",
    "    # 3. اختيار أفضل candidate_size وثيقة للمعالجة الدقيقة\n",
    "    candidate_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)[:candidate_size]\n",
    "    candidate_doc_ids = [doc_id for doc_id, _ in candidate_docs]\n",
    "\n",
    "    # 4. إيجاد إندكسات هذه الوثائق في مصفوفة tfidf_matrix\n",
    "    doc_id_to_index = {doc_id: idx for idx, doc_id in enumerate(doc_ids)}\n",
    "    candidate_indices = [doc_id_to_index[doc_id] for doc_id in candidate_doc_ids if doc_id in doc_id_to_index]\n",
    "\n",
    "    # 5. بناء مصفوفة tfidf للوثائق المرشحة فقط\n",
    "    candidate_tfidf_matrix = tfidf_matrix[candidate_indices]\n",
    "\n",
    "    # 6. تحويل الاستعلام إلى تمثيل tfidf\n",
    "    query_vector = tfidf_vectorizer.transform([cleaned_query])\n",
    "\n",
    "    # 7. حساب cosine similarity بين الاستعلام والوثائق المرشحة فقط\n",
    "    cosine_scores = cosine_similarity(query_vector, candidate_tfidf_matrix).flatten()\n",
    "\n",
    "    # 8. اختيار أفضل top_k وثائق حسب cosine similarity\n",
    "    top_indices = cosine_scores.argsort()[::-1][:top_k]\n",
    "\n",
    "    # 9. تجهيز النتائج للعرض\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        doc_idx = candidate_indices[idx]\n",
    "        doc_id = doc_ids[doc_idx]\n",
    "        doc_text = docs_dict.get(str(doc_id), \"⚠️ نص الوثيقة غير موجود.\")\n",
    "        score = cosine_scores[idx]\n",
    "        results.append((doc_id, doc_text, score))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 🔍 البحث باستخدام BERT فقط\n",
    "# =============================================\n",
    "def search_bert(query, top_k=10):\n",
    "    query_embedding = bert_model.encode([query])\n",
    "    bert_scores = cosine_similarity(query_embedding, bert_embeddings).flatten()\n",
    "\n",
    "    top_indices = np.argsort(bert_scores)[::-1][:top_k]\n",
    "    results = []\n",
    "    for i in top_indices:\n",
    "        doc_id = bert_doc_ids[i]\n",
    "        doc_text = docs_dict.get(doc_id, \"⚠️ نص الوثيقة غير موجود.\")\n",
    "        score = bert_scores[i]\n",
    "        results.append((doc_id, doc_text, score))\n",
    "    return results\n",
    "\n",
    "# =============================================\n",
    "# 🔍 البحث باستخدام الدمج بين TF-IDF و BERT\n",
    "# =============================================\n",
    "def search_hybrid(query, tfidf_weight=0.5, bert_weight=0.5, top_k=10):\n",
    "    assert tfidf_weight + bert_weight == 1.0, \"يجب أن يكون مجموع الأوزان 1.0\"\n",
    "\n",
    "\n",
    "    tfidf_scores = cosine_similarity(tfidf_vectorizer.transform([advanced_preprocess(query)]), tfidf_matrix).flatten()\n",
    "    bert_scores = cosine_similarity(bert_model.encode([query]), bert_embeddings).flatten()\n",
    "\n",
    "    if tfidf_doc_ids != bert_doc_ids:\n",
    "        raise ValueError(\"قوائم doc_ids غير متطابقة بين النموذجين!\")\n",
    "\n",
    "    combined_scores = tfidf_weight * tfidf_scores + bert_weight * bert_scores\n",
    "    top_indices = np.argsort(combined_scores)[::-1][:top_k]\n",
    "\n",
    "    results = []\n",
    "    for i in top_indices:\n",
    "        doc_id = tfidf_doc_ids[i]\n",
    "        doc_text = docs_dict.get(doc_id, \"⚠️ نص الوثيقة غير موجود.\")\n",
    "        score = combined_scores[i]\n",
    "        results.append((doc_id, doc_text, score))\n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 🧪 تجربة البحث\n",
    "# =============================================\n",
    "query = \"I pla football\"\n",
    "\n",
    "# نتائج TF-IDF فقط\n",
    "print(\"📌 Top 10 TF-IDF Results:\")\n",
    "results_tfidf = search_tfidf_with_inverted_index(\n",
    "    query=query,\n",
    "    inverted_index_data=inverted_index_data, \n",
    "    tfidf_vectorizer=tfidf_vectorizer,\n",
    "    tfidf_matrix=tfidf_matrix,\n",
    "    doc_ids=tfidf_doc_ids,\n",
    "    docs_dict=docs_dict,\n",
    "    top_k=10,\n",
    "    candidate_size=100\n",
    ")\n",
    "\n",
    "for doc_id, doc_text, score in results_tfidf:\n",
    "    print(f\"Doc ID: {doc_id}, Score: {score:.4f}\")\n",
    "    print(f\"Text: {doc_text}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# نتائج BERT فقط\n",
    "print(\"\\n📌 Top 10 BERT Results:\")\n",
    "results_bert = search_bert(query)\n",
    "for doc_id, doc_text, score in results_bert:\n",
    "    print(f\"Doc ID: {doc_id}, Score: {score:.4f}\")\n",
    "    print(f\"Text: {doc_text}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# نتائج Hybrid (TF-IDF + BERT)\n",
    "print(\"\\n📌 Top 10 Hybrid Results (TF-IDF 0.4, BERT 0.6):\")\n",
    "results_hybrid = search_hybrid(query, tfidf_weight=0.4, bert_weight=0.6)\n",
    "\n",
    "for doc_id, doc_text, score in results_hybrid:\n",
    "    print(f\"Doc ID: {doc_id}, Score: {score:.4f}\")\n",
    "    print(f\"Text: {doc_text}\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
